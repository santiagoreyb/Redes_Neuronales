# PROYECTO 2 ‚Äì REDES NEURONALES

**Autores:**  
- Santiago Camilo Rey Benavides  
- Tom√°s Figueroa Sierra  
- Santiago Vides Salcedo  
- Jes√∫s Daniel Molina Emiliani  

**Docente:** Julio Omar Palacio Ni√±o  
**Pontificia Universidad Javeriana ‚Äì Facultad de Ingenier√≠a ‚Äì Ingenier√≠a de Sistemas**  
**Bogot√° D.C., 2023**

---

## üìå Descripci√≥n General
Este proyecto analiza la **clasificaci√≥n de la calidad del vino** empleando **redes neuronales feed-forward**, utilizando el dataset *Wine Quality* del repositorio UCI.  
Se comparan tres arquitecturas:
1. **Perceptr√≥n**  
2. **Red Neuronal con 1 capa oculta**  
3. **Red Neuronal con 2 capas ocultas**

El objetivo es evaluar c√≥mo la complejidad de la red afecta las m√©tricas de clasificaci√≥n (accuracy, precisi√≥n, recall, F1-score) y determinar la arquitectura m√°s eficiente.

---

## üéØ Objetivos

### Objetivo General
Dise√±ar y evaluar modelos de redes neuronales para la clasificaci√≥n de la calidad del vino con el dataset UCI *Wine Quality*.

### Objetivos Espec√≠ficos
1. Analizar y comprender las caracter√≠sticas qu√≠micas del dataset.  
2. Preprocesar los datos (limpieza, normalizaci√≥n, codificaci√≥n y manejo de at√≠picos).  
3. Construir modelos de Perceptr√≥n y redes neuronales con una y dos capas ocultas.  
4. Evaluar y comparar m√©tricas de rendimiento: **accuracy, precisi√≥n, recall y F1-score**.  
5. Analizar el efecto de distintas proporciones de entrenamiento y prueba sobre el desempe√±o.

---

## üß™ Dataset
- **Fuente:** [UCI Machine Learning Repository ‚Äì Wine Quality](https://archive.ics.uci.edu/ml/datasets/Wine+Quality)
- **Tipo:** Vinos blancos (principal) y combinaci√≥n blanco/rojo para prueba adicional (‚Äúbono‚Äù).
- **Caracter√≠sticas:** 11 variables qu√≠micas (acidez, az√∫car residual, alcohol, pH, etc.) + variable objetivo **Quality** (0‚Äì10).

---

## üîÑ Preprocesamiento
- Eliminaci√≥n de registros repetidos.  
- Uni√≥n de datasets (blanco + rojo) para experimento adicional.  
- Detecci√≥n y eliminaci√≥n de outliers con rangos intercuart√≠licos.  
- Normalizaci√≥n de caracter√≠sticas num√©ricas.  
- Selecci√≥n de variables relevantes seg√∫n regresi√≥n lineal.

---

## üèóÔ∏è Modelado
Se implementaron tres arquitecturas en **TensorFlow/Keras**:

| Modelo                       | Capas ocultas | Activaci√≥n | √âpocas |
|-------------------------------|--------------|-----------|-------|
| Perceptr√≥n                    | 0            | lineal    | 100   |
| Red Neuronal 1 capa           | 1 (sigmoid)  | softmax   | 200   |
| Red Neuronal 2 capas          | 2 (sigmoid)  | softmax   | 200   |

- **Divisi√≥n de datos:** 70% entrenamiento / 30% prueba.

---

## üìä Resultados Principales

| Modelo                     | Accuracy | Precisi√≥n | Recall | F1-Score |
|-----------------------------|---------:|---------:|------:|--------:|
| Perceptr√≥n                 | 0.52     | 0.48     | 0.52  | 0.48    |
| Red Neuronal 1 capa        | **0.54** | **0.51** | **0.55** | **0.52** |
| Red Neuronal 2 capas       | 0.52     | 0.49     | 0.52  | 0.45    |
| 2 capas (vino blanco + rojo)| **0.59** | 0.56     | 0.59  | 0.57    |

‚úÖ **Conclusi√≥n:**  
La red con **una sola capa oculta** mostr√≥ un equilibrio ligeramente mejor entre precisi√≥n y recall.  
Al combinar vinos blancos y rojos se logr√≥ la mejor accuracy (0.59) gracias a un mayor volumen de datos.

---

## üß† Conclusiones
1. **Exploraci√≥n exhaustiva del dataset** permiti√≥ seleccionar atributos clave para la clasificaci√≥n.  
2. El **preprocesamiento de datos** (limpieza y normalizaci√≥n) fue cr√≠tico para obtener resultados estables.  
3. No se observaron diferencias dr√°sticas entre arquitecturas; **aumentar la complejidad no garantiz√≥ mejoras**.  
4. La red de **una capa oculta** es suficiente para este problema con los datos actuales.  
5. Mayor cantidad y diversidad de datos podr√≠a mejorar significativamente el rendimiento.

---

## üìé Enlace al Notebook
[Google Colab ‚Äì C√≥digo del Proyecto](https://colab.research.google.com/drive/1Kn6tFDdMZ_bD19kTtLdsZ6xLriITkjSE?usp=sharing)

---

## üõ†Ô∏è Tecnolog√≠as
- **Lenguaje:** Python  
- **Librer√≠as principales:** TensorFlow, Keras, Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn

---

**Palabras clave:** Redes Neuronales, Clasificaci√≥n, Wine Quality, TensorFlow, Machine Learning

